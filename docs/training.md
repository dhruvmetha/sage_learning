# Training Guide

## Prerequisites

1. **Environment**: Activate the mjxrl conda environment
   ```bash
   conda activate /common/users/dm1487/envs/mjxrl
   ```

2. **Data**: Prepare .npz files from NAMO data collection
   - Generated by `namo/python/namo/visualization/mask_generation/batch_collection.py`
   - Each file contains scene images and ground truth masks

## Quick Start

### Flow Matching (Facebook)
```bash
cd /common/home/dm1487/robotics_research/ktamp/sage_learning

# Install Facebook's flow_matching library (first time only)
pip install flow-matching torchdyn

# Single GPU (default)
python src/train_generative.py --config-name=train_fb_flow_matching

# Multi-GPU
python src/train_generative.py --config-name=train_fb_flow_matching trainer=multi_gpu

# With adaptive ODE solver (dopri5)
python src/train_generative.py --config-name=train_fb_flow_matching model.sampler.method=dopri5
```

### Diffusion (HuggingFace)
```bash
# Install HuggingFace diffusers (first time only)
pip install diffusers

# DDIM (deterministic, faster) - default
python src/train_generative.py --config-name=train_hf_diffusion

# DDPM (stochastic)
python src/train_generative.py --config-name=train_hf_diffusion model.sampler.sampler_type=ddpm
```

## Training Configurations

| Config | Objective | Library | Sampling Steps |
|--------|-----------|---------|----------------|
| `train_fb_flow_matching.yaml` | Flow Matching | Facebook | ~20 |
| `train_hf_diffusion.yaml` | DDPM/DDIM | HuggingFace | ~50 |

### Default Settings
```yaml
seed: 42
batch_size: 64
max_epochs: 1000
base_lr: 0.0001
image_size: 64
```

## Trainer Configurations

### Single GPU (`trainer=single_gpu`)
- Default for training configs
- Mixed precision (`16-mixed`)
- Gradient clipping (1.0)
- TensorBoard logging
- Callbacks: ModelCheckpoint, LearningRateMonitor, RichProgressBar

### Multi-GPU (`trainer=multi_gpu`)
- DDP strategy with optimizations (`static_graph=true`, `find_unused_parameters=false`)
- Synchronized batch normalization
- Auto-detects available GPUs (`devices: auto`)
- Same callbacks as single GPU

```bash
# Use all available GPUs
python src/train_generative.py --config-name=train_fb_flow_matching trainer=multi_gpu

# Use specific number of GPUs
python src/train_generative.py --config-name=train_fb_flow_matching trainer=multi_gpu trainer.devices=4
```

**Note**: Effective batch size = `batch_size * num_gpus`. Consider scaling learning rate accordingly.

## Model Configurations

### Facebook Flow Matching (`model=generative_fb_flow_matching`)
```yaml
_target_: src.model.generative_module.GenerativeModule
network:
  _target_: src.model.dit.dit.DiT
  in_ch: 8      # 5 context + 2 coord_grid + 1 noisy
  out_ch: 1
path:
  _target_: src.model.paths.fb_flow_matching_path.FBFlowMatchingPath
  scheduler: condot  # condot, cosine, vp, linear_vp
sampler:
  _target_: src.model.samplers.fb_ode_sampler.FBODESampler
  method: midpoint  # euler, midpoint, rk4, dopri5
```

### HuggingFace Diffusion (`model=generative_hf_diffusion`)
```yaml
_target_: src.model.generative_module.GenerativeModule
network:
  _target_: src.model.dit.dit.DiT
  in_ch: 8
  out_ch: 1
path:
  _target_: src.model.paths.hf_diffusion_path.HFDiffusionPath
  num_train_timesteps: 1000
  beta_schedule: squaredcos_cap_v2
  prediction_type: epsilon
sampler:
  _target_: src.model.samplers.hf_diffusion_sampler.HFDiffusionSampler
  sampler_type: ddim  # ddim or ddpm
  eta: 0.0  # 0.0 = deterministic DDIM, 1.0 = DDPM-like
```

## Common Overrides

```bash
# Change batch size
python src/train_generative.py --config-name=train_fb_flow_matching batch_size=128

# Change learning rate
python src/train_generative.py --config-name=train_fb_flow_matching base_lr=5e-5

# Change data directory
python src/train_generative.py --config-name=train_fb_flow_matching data.data_dir=/path/to/data

# Change max epochs
python src/train_generative.py --config-name=train_fb_flow_matching max_epochs=500

# Resume from checkpoint
python src/train_generative.py --config-name=train_fb_flow_matching ckpt_path=/path/to/checkpoint.ckpt

# Switch between DDPM/DDIM (HuggingFace diffusion)
python src/train_generative.py --config-name=train_hf_diffusion model.sampler.sampler_type=ddpm

# Change beta schedule (HuggingFace diffusion)
python src/train_generative.py --config-name=train_hf_diffusion model.path.beta_schedule=linear

# Fewer inference steps (HuggingFace diffusion)
python src/train_generative.py --config-name=train_hf_diffusion sampling_steps=20

# Change ODE solver (Facebook flow matching)
python src/train_generative.py --config-name=train_fb_flow_matching model.sampler.method=dopri5

# Change scheduler (Facebook flow matching)
python src/train_generative.py --config-name=train_fb_flow_matching model.path.scheduler=cosine
```

## Monitoring

### TensorBoard
```bash
tensorboard --logdir=outputs/
```

Logged metrics:
- `train_loss`: Training loss (MSE + auxiliary)
- `val_loss`: Validation loss
- `val_loss_best`: Best validation loss
- `Validation_Samples_*`: Generated samples vs ground truth

### Checkpoints

Saved in `outputs/<run_name>/checkpoints/`:
- `last.ckpt`: Latest checkpoint
- `epochXXX-val_lossX.XXXX.ckpt`: Best checkpoints by validation loss

## Data Format

Each .npz file should contain:

| Key | Shape | Description |
|-----|-------|-------------|
| `robot_image` | (224, 224) | Robot position mask |
| `goal_image` | (224, 224) | Robot goal mask |
| `movable_objects_image` | (224, 224) | All movable objects |
| `static_objects_image` | (224, 224) | Walls/static obstacles |
| `target_object` | (224, 224) | Selected object mask |
| `target_goal` | (224, 224) | Ground truth goal mask |

Legacy keys (`robot`, `goal`, `movable`, `static`) are also supported.

## Troubleshooting

### Out of Memory
- Reduce `batch_size`
- Reduce `image_size`
- Ensure `trainer.precision=16-mixed` (default)

### Slow Training
- Increase `num_workers`
- Use `trainer=multi_gpu` for multi-GPU
- Reduce `image_size` to 64

### NaN Loss
- Reduce learning rate (`base_lr=5e-5`)
- Check for corrupted data files
- Gradient clipping is enabled by default (1.0)

### Poor Results
- Train longer (`max_epochs=2000`)
- Increase model capacity (DiT depth/dim)
- Increase auxiliary loss (`model.aux_loss_weight=0.01`)
- Check data quality

## Output Structure

```
outputs/<run_name>/
├── .hydra/
│   └── config.yaml          # Full config for reproducibility
├── checkpoints/
│   ├── last.ckpt
│   └── epochXXX-val_lossX.XXXX.ckpt
└── tensorboard/
    └── events.out.tfevents.*  # TensorBoard logs
```
