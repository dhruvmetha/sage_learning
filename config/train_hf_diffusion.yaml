# Training Configuration for HuggingFace Diffusion
# Uses HuggingFace's diffusers library for DDPM/DDIM
#
# Install dependencies:
#   pip install diffusers
#
# Usage:
#   python src/train_generative.py --config-name=train_hf_diffusion
#
# For DDPM (stochastic) instead of DDIM:
#   python src/train_generative.py --config-name=train_hf_diffusion model.sampler.sampler_type=ddpm
#
# For fewer inference steps (DDIM can handle 20-50 steps):
#   python src/train_generative.py --config-name=train_hf_diffusion sampling_steps=50
#
# Resume training from a checkpoint:
#   python src/train_generative.py --config-name=train_hf_diffusion ckpt_path=/path/to/checkpoint.ckpt

# Experiment name (used in output path)
name: diffusion
output_dir: /common/users/dm1487/namo_data/outputs/${name}
data_dir: /common/users/dm1487/namo_data/h5_files/dec2/aug9_envs/1_push_train

# Resume from checkpoint (set to path to resume training, null to start fresh)
ckpt_path: null

# Hydra output directory structure
hydra:
  run:
    dir: outputs/${name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: outputs/${name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}

defaults:
  - _self_
  - data: mask_diffusion_data
  - model: generative_hf_diffusion
  - trainer: multi_gpu
  - callbacks: default

# Random seed
seed: 42

# Data loading
# Note: HDF5 files can be slow with multiple workers due to file contention
# Try num_workers: 0 first, then increase if it works
num_workers: 0
batch_size: 64

# Training
max_epochs: 1000
check_val_every_n_epoch: 1

# Learning rate schedule
base_lr: 0.0001
end_lr: 0.000001
warmup_steps: 1000
decay_steps: 300000

# Image size
image_size: 64

# Use local (object-centered) masks instead of global
# This controls both data loading and model context building
use_local: true

# GPU (for legacy compatibility)
gpu_id: 0

# Sampling steps for inference
# DDIM can use fewer steps (20-50), DDPM needs more (~100-1000)
sampling_steps: 50

# Paths
# Checkpoints and logs will be saved to output_dir with a timestamp subdirectory
paths:
  output_dir: ${output_dir}/${now:%Y-%m-%d}/${now:%H-%M-%S}
