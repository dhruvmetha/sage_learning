# Single GPU Trainer Configuration
# PyTorch Lightning best practices for single GPU training
#
# Usage:
#   python src/train_generative.py trainer=single_gpu ...

_target_: lightning.pytorch.trainer.Trainer

# Hardware
accelerator: gpu
devices: 1

# Training duration
min_epochs: 1
max_epochs: ${max_epochs}

# Mixed precision for faster training and lower memory
precision: 16-mixed

# Gradient clipping for stable training (important for diffusion/flow matching)
gradient_clip_val: 1.0
gradient_clip_algorithm: norm

# Validation frequency
check_val_every_n_epoch: ${check_val_every_n_epoch}

# Logging
log_every_n_steps: 50
enable_progress_bar: true

# Sanity check before training
num_sanity_val_steps: 2

# Reproducibility (set to true for debugging, false for speed)
deterministic: false

# Callbacks
callbacks:
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${paths.output_dir}/checkpoints
    filename: "epoch{epoch:03d}-val_loss{val_loss:.4f}"
    monitor: val_loss
    mode: min
    save_top_k: 3
    save_last: true
    auto_insert_metric_name: false
    verbose: true

  - _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: step

  - _target_: lightning.pytorch.callbacks.RichProgressBar
    refresh_rate: 10

# Logger
logger:
  - _target_: lightning.pytorch.loggers.TensorBoardLogger
    save_dir: ${paths.output_dir}
    name: tensorboard
    version: ""
    default_hp_metric: false
